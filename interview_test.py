# interviewer_app.py
import os
import threading
import time
from typing import List

import numpy as np
import requests
import soundfile as sf
import simpleaudio as sa
import sounddevice as sd
import torch
import whisper
import uvicorn
from dotenv import load_dotenv
from fastapi import FastAPI, Request, UploadFile, File
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
import tempfile
from silero_vad import load_silero_vad, get_speech_timestamps
from utils import (
    clean_and_extract_ssml,
    sanitize_ssml_for_silero,
    ssml_to_plain_text,
    extract_text,
    load_job_requirements,
    strip_thinking_tags
)
import json
STOP_WORDS = ["—Å—Ç–æ–ø", "–∑–∞–∫–æ–Ω—á–∏–º", "—Ö–≤–∞—Ç–∏—Ç", "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ", "–∑–∞–≤–µ—Ä—à–∏–º"]

# ============================ –ö–æ–Ω—Ñ–∏–≥ ============================

load_dotenv()
API_BASE_URL = os.getenv("API_BASE_URL", "http://127.0.0.1:8080/v1")
MODEL_NAME   = os.getenv("MODEL_NAME", "llama-2-7b-chat")
JOB_DESCRIPTION_PATH = os.getenv("JOB_DESCRIPTION_PATH")

SAMPLERATE   = 16000
CHUNK_SEC    = 1
PAUSE_CHUNKS = 2
TTS_SR       = 48000
TTS_SPEAKER  = "kseniya"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
if DEVICE == "cuda":
    torch.set_float32_matmul_precision("high")
_dialogue_history: List[dict] = []
# ============================ –°–æ—Å—Ç–æ—è–Ω–∏–µ ============================

app = FastAPI()
templates = Jinja2Templates(directory="templates")

_interview_running = False
_speaking = False
_log: List[str] = []
_lock = threading.Lock()
_system_prompt = None  # –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ

# ============================ –ú–æ–¥–µ–ª–∏ ============================

vad_model = load_silero_vad(onnx=False)
_VAD_DEVICE = "cpu"

stt_model = whisper.load_model("small", device=DEVICE)

tts_device = torch.device(DEVICE)
tts_model, _ = torch.hub.load(
    "snakers4/silero-models",
    model="silero_tts",
    language="ru",
    speaker="v4_ru"
)
tts_model.to(tts_device)

# ============================ –£—Ç–∏–ª–∏—Ç—ã ============================

def log_line(text: str):
    with _lock:
        print(text)
        _log.append(text)

# interviewer_app.py
import os
import threading
import time
from typing import List

import numpy as np
import requests
import soundfile as sf
import simpleaudio as sa
import sounddevice as sd
import torch
import whisper
import uvicorn
from dotenv import load_dotenv
from fastapi import FastAPI, Request, UploadFile, File
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
import tempfile
from silero_vad import load_silero_vad, get_speech_timestamps
from utils import (
    clean_and_extract_ssml,
    sanitize_ssml_for_silero,
    ssml_to_plain_text,
    extract_text,
    load_job_requirements,
    strip_thinking_tags
)
import json
STOP_WORDS = ["—Å—Ç–æ–ø", "–∑–∞–∫–æ–Ω—á–∏–º", "—Ö–≤–∞—Ç–∏—Ç", "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ", "–∑–∞–≤–µ—Ä—à–∏–º"]

# ============================ –ö–æ–Ω—Ñ–∏–≥ ============================

load_dotenv()
API_BASE_URL = os.getenv("API_BASE_URL", "http://127.0.0.1:8080/v1")
MODEL_NAME   = os.getenv("MODEL_NAME", "llama-2-7b-chat")
JOB_DESCRIPTION_PATH = os.getenv("JOB_DESCRIPTION_PATH")

SAMPLERATE   = 16000
CHUNK_SEC    = 1
PAUSE_CHUNKS = 2
TTS_SR       = 48000
TTS_SPEAKER  = "kseniya"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
if DEVICE == "cuda":
    torch.set_float32_matmul_precision("high")
_dialogue_history: List[dict] = []
# ============================ –°–æ—Å—Ç–æ—è–Ω–∏–µ ============================

app = FastAPI()
templates = Jinja2Templates(directory="templates")

_interview_running = False
_speaking = False
_log: List[str] = []
_lock = threading.Lock()
_system_prompt = None  # –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ

# ============================ –ú–æ–¥–µ–ª–∏ ============================

vad_model = load_silero_vad(onnx=False)
_VAD_DEVICE = "cpu"

stt_model = whisper.load_model("small", device=DEVICE)

tts_device = torch.device(DEVICE)
tts_model, _ = torch.hub.load(
    "snakers4/silero-models",
    model="silero_tts",
    language="ru",
    speaker="v4_ru"
)
tts_model.to(tts_device)

# ============================ –£—Ç–∏–ª–∏—Ç—ã ============================

def log_line(text: str):
    with _lock:
        print(text)
        _log.append(text)

def check_end_dialogue(user_text: str, assistant_text: str) -> bool:
    """
    –°–ø—Ä–∞—à–∏–≤–∞–µ–º —É –º–æ–¥–µ–ª–∏: –∑–∞–∫–æ–Ω—á–µ–Ω–æ –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é?
    –û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ JSON: {"end": 0} –∏–ª–∏ {"end": 1}
    """
    try:
        prompt = f"""
–¢—ã –±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä. 
–í—Ö–æ–¥: —Ä–µ–ø–ª–∏–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ –æ—Ç–≤–µ—Ç –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞.
–û–ø—Ä–µ–¥–µ–ª–∏, –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é. 

–ü—Ä–∞–≤–∏–ª–∞:
- –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç —è–≤–Ω–æ —Å–∫–∞–∑–∞–ª "—Å—Ç–æ–ø", "–∑–∞–∫–æ–Ω—á–∏–º", "—Ö–≤–∞—Ç–∏—Ç" –∏ —Ç.–ø. ‚Üí end=1
- –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä —Å–∫–∞–∑–∞–ª, —á—Ç–æ –≤—Å—ë –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Üí end=1
- –ò–Ω–∞—á–µ ‚Üí end=0

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ —Å—Ç—Ä–æ–≥–æ JSON:
{{"end": 0}} –∏–ª–∏ {{"end": 1}}

–†–µ–ø–ª–∏–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:
{user_text}

–†–µ–ø–ª–∏–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞:
{assistant_text}
"""
        payload = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt}]}
        r = requests.post(f"{API_BASE_URL}/chat/completions", json=payload, timeout=30)
        r.raise_for_status()
        raw = r.json()["choices"][0]["message"]["content"]
        parsed = json.loads(strip_thinking_tags(raw))
        return parsed.get("end", 0) == 1
    except Exception as e:
        log_line(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ check_end_dialogue: {e}")
        return False


def ask_llm(user_text: str) -> str:
    global _system_prompt, _dialogue_history, _interview_running

    if not _dialogue_history:
        _dialogue_history.append({"role": "system", "content": _system_prompt})

    _dialogue_history.append({"role": "user", "content": user_text})

    payload = {"model": MODEL_NAME, "messages": _dialogue_history, "temperature": 0.4}
    r = requests.post(f"{API_BASE_URL}/chat/completions", json=payload, timeout=60)
    r.raise_for_status()
    raw = r.json()["choices"][0]["message"]["content"]

    _dialogue_history.append({"role": "assistant", "content": raw})

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤—å—é
    if check_end_dialogue(user_text, raw):
        log_line("üìä –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–µ—à–∏–ª–∞: –∏–Ω—Ç–µ—Ä–≤—å—é –∑–∞–∫–æ–Ω—á–µ–Ω–æ.")
        # –ó–∞–ø—Ä–æ—Å –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞
        prompt_report = """
        –ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ 
        —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
          "–ö—Ä–∏—Ç–µ—Ä–∏–∏": {
            "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
            "–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
            "–ú–æ—Ç–∏–≤–∞—Ü–∏—è –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
          },
          "–û–±—â–∏–π –≤—ã–≤–æ–¥": "—Ç–µ–∫—Å—Ç–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ"
        }
        """
        payload = {"model": MODEL_NAME, "messages": [
            {"role": "system", "content": _system_prompt},
            {"role": "user", "content": prompt_report}
        ]}
        r = requests.post(f"{API_BASE_URL}/chat/completions", json=payload, timeout=60)
        r.raise_for_status()
        report_raw = r.json()["choices"][0]["message"]["content"]
        log_line("üìä –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç:\n" + report_raw)
        _interview_running = False
        return "<speak><p><s>–°–ø–∞—Å–∏–±–æ –∑–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ! –ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç.</s></p></speak>"

    return clean_and_extract_ssml(raw)

def speak_ssml(ssml_text: str, filename="tts_output.wav"):
    global _speaking
    _speaking = True
    try:
        silero_text = sanitize_ssml_for_silero(ssml_text)
        audio = tts_model.apply_tts(text=silero_text, speaker=TTS_SPEAKER, sample_rate=TTS_SR)
    except Exception as e:
        log_line(f"‚ö†Ô∏è SSML –Ω–µ –ø—Ä–∏–Ω—è—Ç ({e}). Fallback –≤ —Ç–µ–∫—Å—Ç.")
        plain = ssml_to_plain_text(ssml_text)
        audio = tts_model.apply_tts(text=plain, speaker=TTS_SPEAKER, sample_rate=TTS_SR)

    sf.write(filename, audio, TTS_SR)
    play_obj = sa.WaveObject.from_wave_file(filename).play()
    while play_obj.is_playing():
        time.sleep(0.05)
    time.sleep(0.3)
    _speaking = False

# ============================ –õ–æ–≥–∏–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é ============================

def interview_loop():
    global _interview_running, _speaking

    log_line(f"üñ•Ô∏è Whisper: {DEVICE} | TTS: {DEVICE} | VAD: {_VAD_DEVICE}")
    buffer = []
    silence_count = 0
    log_line("üé§ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å. –ì–æ–≤–æ—Ä–∏—Ç–µ...")

    while _interview_running:
        if _speaking:
            buffer = []
            silence_count = 0
            time.sleep(0.05)
            continue

        audio = sd.rec(int(SAMPLERATE * CHUNK_SEC), samplerate=SAMPLERATE, channels=1, dtype="float32")
        sd.wait()
        audio = audio.flatten()

        x = torch.tensor(audio, dtype=torch.float32, device=_VAD_DEVICE)
        speech_ts = get_speech_timestamps(x, vad_model, sampling_rate=SAMPLERATE)

        if len(speech_ts) == 0:
            silence_count += 1
            if silence_count >= PAUSE_CHUNKS and len(buffer) > 0:
                chunk = np.concatenate(buffer)
                if np.max(np.abs(chunk)) > 0:
                    chunk = chunk / np.max(np.abs(chunk))

                result = stt_model.transcribe(chunk, language="ru", fp16=(DEVICE == "cuda"))
                user_text = result["text"].strip()
                log_line(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_text}")

                try:
                    assistant_ssml = ask_llm(user_text)
                    log_line(f"ü§ñ –ò–Ω—Ç–µ—Ä–≤—å—é–µ—Ä (SSML): {assistant_ssml}")
                    speak_ssml(assistant_ssml)
                except Exception as e:
                    log_line(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM/TTS: {e}")

                buffer = []
                silence_count = 0
        else:
            silence_count = 0
            buffer.append(audio)

        time.sleep(0.01)

    log_line("‚èπ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")

# ============================ –†–æ—É—Ç—ã ============================

@app.get("/", response_class=HTMLResponse)
def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})
JOB_DESCRIPTION_PATH = os.getenv("JOB_DESCRIPTION_PATH")
JOB_REQUIREMENTS = load_job_requirements(JOB_DESCRIPTION_PATH)

@app.post("/api/upload_resume")
async def upload_resume(file: UploadFile = File(...)):
    global _system_prompt
    try:
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        tmp_dir = tempfile.gettempdir()
        save_path = os.path.join(tmp_dir, file.filename)
        with open(save_path, "wb") as f:
            f.write(await file.read())

        # –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ
        resume_text = extract_text(save_path)
        if not resume_text.strip():
            return JSONResponse({"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞."}, status_code=400)

        # --- 1) –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π ---
        prompt_analysis = f"""
–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç. –£ —Ç–µ–±—è –µ—Å—Ç—å —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–∏.
–û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–∫–∞–∫ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏–∂–µ).

–†–µ–∑—é–º–µ:
{resume_text}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
{json.dumps(JOB_REQUIREMENTS, ensure_ascii=False, indent=2)}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
–í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏ "–û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π", "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", "–û–±—â–∏–π –≤—ã–≤–æ–¥".
"""
        payload = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt_analysis}]}
        resp = requests.post(f"{API_BASE_URL}/chat/completions", json=payload)
        resp.raise_for_status()
        raw_analysis = resp.json()["choices"][0]["message"]["content"]
        clean_analysis = strip_thinking_tags(raw_analysis)

        # --- 2) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ ---
        prompt_questions = f"""
–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç. –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø—Ä–∏–¥—É–º–∞–π 2 –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤,
–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç —É—Ç–æ—á–Ω–∏—Ç—å —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ —Ä–∞—Å–∫—Ä—ã—Ç—å –µ–≥–æ –æ–ø—ã—Ç.

–ê–Ω–∞–ª–∏–∑:
{clean_analysis}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
JSON:
{{
  "–í–æ–ø—Ä–æ—Å—ã": [
    "–í–æ–ø—Ä–æ—Å 1",
    "–í–æ–ø—Ä–æ—Å 2",
    "...",
    "–í–æ–ø—Ä–æ—Å 7"
  ]
}}
"""
        payload_q = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt_questions}]}
        resp_q = requests.post(f"{API_BASE_URL}/chat/completions", json=payload_q)
        resp_q.raise_for_status()
        raw_q = resp_q.json()["choices"][0]["message"]["content"]
        clean_q = strip_thinking_tags(raw_q)

        # --- —Å–æ–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞ ---
        _system_prompt = f"""
        –¢—ã –∏–≥—Ä–∞–µ—à—å —Ä–æ–ª—å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞. 
        –¢–≤–æ—è —Ü–µ–ª—å ‚Äì –≤–µ—Å—Ç–∏ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ –∏ —Å–ø–∏—Å–æ–∫ –∑–∞—Ä–∞–Ω–µ–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.

        –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:
        {clean_analysis}

        –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:
        {clean_q}

        –ü—Ä–∞–≤–∏–ª–∞:
        - –ì–æ–≤–æ—Ä–∏ —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ä–µ–ø–ª–∏–∫–∞–º–∏.
        - –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π SSML (<speak>...</speak>).
        - –í—Å—Ç–∞–≤–ª—è–π –ø–∞—É–∑—ã –∏ —ç–º–æ—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é <break>, <prosody>, <emphasis>.
        - –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ø–æ—Ä—è–¥–∫—É, –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–≥–æ.
        - ‚ö†Ô∏è –í—Å–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π) –ø–∏—à–∏ –≤ —Ä—É—Å—Å–∫–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏,
          —á—Ç–æ–±—ã —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä —Ä–µ—á–∏ –ø—Ä–æ–∏–∑–Ω—ë—Å –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –ü—Ä–∏–º–µ—Ä: "TensorFlow" ‚Üí "–¢√©–Ω—Å–æ—Ä—Ñ–ª–æ—É", "PyTorch" ‚Üí "–ü–∞–π—Ç√≥—Ä—á".
        """

        return JSONResponse({
            "analysis": clean_analysis,
            "questions": clean_q
        })
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

@app.post("/api/start")
def api_start():
    global _interview_running, _log, _system_prompt, _dialogue_history
    if not _system_prompt:
        return JSONResponse({"status": "error", "message": "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ"}, status_code=400)

    with _lock:
        if not _interview_running:
            _log = []
            _dialogue_history = []   # <<< –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
            _interview_running = True
            threading.Thread(target=interview_loop, daemon=True).start()
            return JSONResponse({"status": "started"})
    return JSONResponse({"status": "already running"})

@app.post("/api/stop")
def api_stop():
    global _interview_running
    with _lock:
        _interview_running = False
    return JSONResponse({"status": "stopped"})

@app.get("/api/speaking")
def api_speaking():
    return JSONResponse({"speaking": _speaking})

@app.get("/api/logs")
def api_logs():
    with _lock:
        return JSONResponse({"dialogue": "\n".join(_log)})

# ============================ –ó–∞–ø—É—Å–∫ ============================

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8081)



def ask_llm(user_text: str) -> str:
    global _system_prompt, _dialogue_history, _interview_running

    if not _dialogue_history:
        _dialogue_history.append({"role": "system", "content": _system_prompt})

    _dialogue_history.append({"role": "user", "content": user_text})

    payload = {"model": MODEL_NAME, "messages": _dialogue_history, "temperature": 0.4}
    r = requests.post(f"{API_BASE_URL}/chat/completions", json=payload, timeout=60)
    r.raise_for_status()
    raw = r.json()["choices"][0]["message"]["content"]

    _dialogue_history.append({"role": "assistant", "content": raw})

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤—å—é
    if check_end_dialogue(user_text, raw):
        log_line("üìä –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–µ—à–∏–ª–∞: –∏–Ω—Ç–µ—Ä–≤—å—é –∑–∞–∫–æ–Ω—á–µ–Ω–æ.")
        # –ó–∞–ø—Ä–æ—Å –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞
        prompt_report = """
        –ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ 
        —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
          "–ö—Ä–∏—Ç–µ—Ä–∏–∏": {
            "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
            "–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
            "–ú–æ—Ç–∏–≤–∞—Ü–∏—è –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª": "–æ—Ü–µ–Ω–∫–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
          },
          "–û–±—â–∏–π –≤—ã–≤–æ–¥": "—Ç–µ–∫—Å—Ç–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ"
        }
        """
        payload = {"model": MODEL_NAME, "messages": [
            {"role": "system", "content": _system_prompt},
            {"role": "user", "content": prompt_report}
        ]}
        r = requests.post(f"{API_BASE_URL}/chat/completions", json=payload, timeout=60)
        r.raise_for_status()
        report_raw = r.json()["choices"][0]["message"]["content"]
        log_line("üìä –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç:\n" + report_raw)
        _interview_running = False
        return "<speak><p><s>–°–ø–∞—Å–∏–±–æ –∑–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ! –ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç.</s></p></speak>"

    return clean_and_extract_ssml(raw)

def speak_ssml(ssml_text: str, filename="tts_output.wav"):
    global _speaking
    _speaking = True
    try:
        silero_text = sanitize_ssml_for_silero(ssml_text)
        audio = tts_model.apply_tts(text=silero_text, speaker=TTS_SPEAKER, sample_rate=TTS_SR)
    except Exception as e:
        log_line(f"‚ö†Ô∏è SSML –Ω–µ –ø—Ä–∏–Ω—è—Ç ({e}). Fallback –≤ —Ç–µ–∫—Å—Ç.")
        plain = ssml_to_plain_text(ssml_text)
        audio = tts_model.apply_tts(text=plain, speaker=TTS_SPEAKER, sample_rate=TTS_SR)

    sf.write(filename, audio, TTS_SR)
    play_obj = sa.WaveObject.from_wave_file(filename).play()
    while play_obj.is_playing():
        time.sleep(0.05)
    time.sleep(0.3)
    _speaking = False

# ============================ –õ–æ–≥–∏–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é ============================

def interview_loop():
    global _interview_running, _speaking

    log_line(f"üñ•Ô∏è Whisper: {DEVICE} | TTS: {DEVICE} | VAD: {_VAD_DEVICE}")
    buffer = []
    silence_count = 0
    log_line("üé§ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å. –ì–æ–≤–æ—Ä–∏—Ç–µ...")

    while _interview_running:
        if _speaking:
            buffer = []
            silence_count = 0
            time.sleep(0.05)
            continue

        audio = sd.rec(int(SAMPLERATE * CHUNK_SEC), samplerate=SAMPLERATE, channels=1, dtype="float32")
        sd.wait()
        audio = audio.flatten()

        x = torch.tensor(audio, dtype=torch.float32, device=_VAD_DEVICE)
        speech_ts = get_speech_timestamps(x, vad_model, sampling_rate=SAMPLERATE)

        if len(speech_ts) == 0:
            silence_count += 1
            if silence_count >= PAUSE_CHUNKS and len(buffer) > 0:
                chunk = np.concatenate(buffer)
                if np.max(np.abs(chunk)) > 0:
                    chunk = chunk / np.max(np.abs(chunk))

                result = stt_model.transcribe(chunk, language="ru", fp16=(DEVICE == "cuda"))
                user_text = result["text"].strip()
                log_line(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_text}")

                try:
                    assistant_ssml = ask_llm(user_text)
                    log_line(f"ü§ñ –ò–Ω—Ç–µ—Ä–≤—å—é–µ—Ä (SSML): {assistant_ssml}")
                    speak_ssml(assistant_ssml)
                except Exception as e:
                    log_line(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM/TTS: {e}")

                buffer = []
                silence_count = 0
        else:
            silence_count = 0
            buffer.append(audio)

        time.sleep(0.01)

    log_line("‚èπ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")

# ============================ –†–æ—É—Ç—ã ============================

@app.get("/", response_class=HTMLResponse)
def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})
JOB_DESCRIPTION_PATH = os.getenv("JOB_DESCRIPTION_PATH")
JOB_REQUIREMENTS = load_job_requirements(JOB_DESCRIPTION_PATH)

@app.post("/api/upload_resume")
async def upload_resume(file: UploadFile = File(...)):
    global _system_prompt
    try:
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        tmp_dir = tempfile.gettempdir()
        save_path = os.path.join(tmp_dir, file.filename)
        with open(save_path, "wb") as f:
            f.write(await file.read())

        # –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ
        resume_text = extract_text(save_path)
        if not resume_text.strip():
            return JSONResponse({"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞."}, status_code=400)

        # --- 1) –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π ---
        prompt_analysis = f"""
–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç. –£ —Ç–µ–±—è –µ—Å—Ç—å —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–∏.
–û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–∫–∞–∫ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏–∂–µ).

–†–µ–∑—é–º–µ:
{resume_text}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
{json.dumps(JOB_REQUIREMENTS, ensure_ascii=False, indent=2)}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
–í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏ "–û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π", "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", "–û–±—â–∏–π –≤—ã–≤–æ–¥".
"""
        payload = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt_analysis}]}
        resp = requests.post(f"{API_BASE_URL}/chat/completions", json=payload)
        resp.raise_for_status()
        raw_analysis = resp.json()["choices"][0]["message"]["content"]
        clean_analysis = strip_thinking_tags(raw_analysis)

        # --- 2) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ ---
        prompt_questions = f"""
–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç. –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø—Ä–∏–¥—É–º–∞–π 2 –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤,
–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç —É—Ç–æ—á–Ω–∏—Ç—å —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ —Ä–∞—Å–∫—Ä—ã—Ç—å –µ–≥–æ –æ–ø—ã—Ç.

–ê–Ω–∞–ª–∏–∑:
{clean_analysis}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
JSON:
{{
  "–í–æ–ø—Ä–æ—Å—ã": [
    "–í–æ–ø—Ä–æ—Å 1",
    "–í–æ–ø—Ä–æ—Å 2",
    "...",
    "–í–æ–ø—Ä–æ—Å 7"
  ]
}}
"""
        payload_q = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt_questions}]}
        resp_q = requests.post(f"{API_BASE_URL}/chat/completions", json=payload_q)
        resp_q.raise_for_status()
        raw_q = resp_q.json()["choices"][0]["message"]["content"]
        clean_q = strip_thinking_tags(raw_q)

        # --- —Å–æ–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞ ---
        _system_prompt = f"""
        –¢—ã –∏–≥—Ä–∞–µ—à—å —Ä–æ–ª—å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞. 
        –¢–≤–æ—è —Ü–µ–ª—å ‚Äì –≤–µ—Å—Ç–∏ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ –∏ —Å–ø–∏—Å–æ–∫ –∑–∞—Ä–∞–Ω–µ–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.

        –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:
        {clean_analysis}

        –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤:
        {clean_q}

        –ü—Ä–∞–≤–∏–ª–∞:
        - –ì–æ–≤–æ—Ä–∏ —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ä–µ–ø–ª–∏–∫–∞–º–∏.
        - –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π SSML (<speak>...</speak>).
        - –í—Å—Ç–∞–≤–ª—è–π –ø–∞—É–∑—ã –∏ —ç–º–æ—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é <break>, <prosody>, <emphasis>.
        - –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ø–æ—Ä—è–¥–∫—É, –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–≥–æ.
        - ‚ö†Ô∏è –í—Å–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π) –ø–∏—à–∏ –≤ —Ä—É—Å—Å–∫–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏,
          —á—Ç–æ–±—ã —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä —Ä–µ—á–∏ –ø—Ä–æ–∏–∑–Ω—ë—Å –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –ü—Ä–∏–º–µ—Ä: "TensorFlow" ‚Üí "–¢√©–Ω—Å–æ—Ä—Ñ–ª–æ—É", "PyTorch" ‚Üí "–ü–∞–π—Ç√≥—Ä—á".
        """

        return JSONResponse({
            "analysis": clean_analysis,
            "questions": clean_q
        })
    except Exception as e:
        return JSONResponse({"error": str(e)}, status_code=500)

@app.post("/api/start")
def api_start():
    global _interview_running, _log, _system_prompt, _dialogue_history
    if not _system_prompt:
        return JSONResponse({"status": "error", "message": "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ"}, status_code=400)

    with _lock:
        if not _interview_running:
            _log = []
            _dialogue_history = []   # <<< –æ—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
            _interview_running = True
            threading.Thread(target=interview_loop, daemon=True).start()
            return JSONResponse({"status": "started"})
    return JSONResponse({"status": "already running"})

@app.post("/api/stop")
def api_stop():
    global _interview_running
    with _lock:
        _interview_running = False
    return JSONResponse({"status": "stopped"})

@app.get("/api/speaking")
def api_speaking():
    return JSONResponse({"speaking": _speaking})

@app.get("/api/logs")
def api_logs():
    with _lock:
        return JSONResponse({"dialogue": "\n".join(_log)})

# ============================ –ó–∞–ø—É—Å–∫ ============================

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8081)
